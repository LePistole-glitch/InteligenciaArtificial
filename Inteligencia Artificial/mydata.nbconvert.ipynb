{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-17T16:30:34.444208Z",
     "iopub.status.busy": "2023-11-17T16:30:34.443839Z",
     "iopub.status.idle": "2023-11-17T16:30:55.369850Z",
     "shell.execute_reply": "2023-11-17T16:30:55.368455Z"
    },
    "id": "9Q2Y3QT520zX"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-17 10:30:39.833997: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-11-17 10:30:39.834129: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-11-17 10:30:39.839952: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-11-17 10:30:40.600313: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding,LSTM,Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "####\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-17T16:30:55.374483Z",
     "iopub.status.busy": "2023-11-17T16:30:55.373168Z",
     "iopub.status.idle": "2023-11-17T16:30:55.379626Z",
     "shell.execute_reply": "2023-11-17T16:30:55.378774Z"
    },
    "id": "IcNfkLgO5eON"
   },
   "outputs": [],
   "source": [
    "#SET DE DATOS\n",
    "from tensorflow.keras.datasets import imdb\n",
    "\n",
    "#Cargar el conjuneto de datos de comentaris de peliculas\n",
    "max_words = 10000 #numero max de palabras a considerando\n",
    "maxlen = 100 #longitud axima de ecuencia de texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2023-11-17T16:30:55.383762Z",
     "iopub.status.busy": "2023-11-17T16:30:55.382833Z",
     "iopub.status.idle": "2023-11-17T16:31:04.357446Z",
     "shell.execute_reply": "2023-11-17T16:31:04.356357Z"
    },
    "id": "pMSLPdr76A36",
    "outputId": "0005b358-4950-427b-aee4-a5ee01b3651d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-17 10:31:00.155908: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-11-17 10:31:00.857105: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-11-17 10:31:00.857153: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-11-17 10:31:00.871204: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-11-17 10:31:00.871309: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-11-17 10:31:00.871332: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-11-17 10:31:01.341827: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-11-17 10:31:01.341931: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-11-17 10:31:01.341948: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1977] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2023-11-17 10:31:01.341991: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-11-17 10:31:01.342030: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 2259 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1650, pci bus id: 0000:01:00.0, compute capability: 7.5\n",
      "2023-11-17 10:31:03.337709: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train),(x_test,y_test) = imdb.load_data(num_words=max_words)\n",
    "x_train = pad_sequences(x_train, maxlen=maxlen)\n",
    "x_test = pad_sequences(x_test, maxlen=maxlen)\n",
    "#Construir el modelo de RNN\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_words,128)) #CAPA DE ENTRADA\n",
    "model.add(LSTM(64)) #CAPA INTERMEDIA\n",
    "model.add(Dense(1,activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-17T16:31:04.361934Z",
     "iopub.status.busy": "2023-11-17T16:31:04.361474Z",
     "iopub.status.idle": "2023-11-17T16:31:04.378639Z",
     "shell.execute_reply": "2023-11-17T16:31:04.377340Z"
    },
    "id": "eXelsPkw82PG"
   },
   "outputs": [],
   "source": [
    "#Compilar el modelo\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss=\"binary_crossentropy\", metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2023-11-17T16:31:04.383074Z",
     "iopub.status.busy": "2023-11-17T16:31:04.382206Z",
     "iopub.status.idle": "2023-11-17T16:31:36.039739Z",
     "shell.execute_reply": "2023-11-17T16:31:36.038613Z"
    },
    "id": "EP98_3dX-ZN8",
    "outputId": "ebe6e34d-65e6-413d-d017-c1829a98a4cd"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-17 10:31:07.132704: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:442] Loaded cuDNN version 8700\n",
      "2023-11-17 10:31:08.816684: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f402c325270 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-11-17 10:31:08.816750: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce GTX 1650, Compute Capability 7.5\n",
      "2023-11-17 10:31:09.249808: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1/391 [..............................] - ETA: 37:34 - loss: 0.6939 - accuracy: 0.4531"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-17 10:31:10.332087: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 31s 66ms/step - loss: 0.4124 - accuracy: 0.8060 - val_loss: 0.3548 - val_accuracy: 0.8430\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7f41071cb790>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#entrenar el modelo\n",
    "model.fit(x_train, y_train, validation_data=(x_test, y_test),batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2023-11-17T16:31:36.058680Z",
     "iopub.status.busy": "2023-11-17T16:31:36.058390Z",
     "iopub.status.idle": "2023-11-17T16:31:43.941983Z",
     "shell.execute_reply": "2023-11-17T16:31:43.940827Z"
    },
    "id": "1nZzHnc8--yi",
    "outputId": "caf83915-9c3c-4129-cdac-bad133498524"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 8s 10ms/step - loss: 0.3548 - accuracy: 0.8430\n",
      "84.30399894714355\n"
     ]
    }
   ],
   "source": [
    "#evaluacion del modelo\n",
    "loss,accurancy = model.evaluate(x_test, y_test)\n",
    "\n",
    "print(accurancy * 100)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
